{"ast":null,"code":"var _jsxFileName = \"/Users/alberttian/f21/playground/frontend/fencing-ai-frontend/src/components/Camera.jsx\",\n    _s = $RefreshSig$();\n\nimport React, { useRef, useEffect } from \"react\";\nimport \"@tensorflow/tfjs-core\";\nimport \"@tensorflow/tfjs-backend-webgl\";\nimport \"@tensorflow/tfjs-backend-wasm\";\nimport * as poseDetection from \"@tensorflow-models/pose-detection\";\nimport Webcam from \"react-webcam\";\nimport { drawResults } from \"../utils/drawUtils\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst videoDim = {\n  width: 640,\n  height: 380\n};\nlet rafId;\nlet webcam, detector;\nlet canvas, ctx;\nexport default function Camera() {\n  _s();\n\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  function setupCamera() {\n    webcam = webcamRef.current;\n    console.log(`webcam width: ${webcam.video.width}`);\n    console.log(`webcam width: ${webcam.video.videoWidth}`);\n    canvas = canvasRef.current;\n    ctx = canvas.getContext(\"2d\");\n    ctx.translate(videoDim.width, 0);\n    ctx.scale(-1, 1);\n  }\n\n  async function setupDetector() {\n    const model = poseDetection.SupportedModels.MoveNet;\n    const detectorConfig = {\n      modelType: poseDetection.movenet.modelType.MULTIPOSE_LIGHTNING,\n      minPoseScore: 0.2,\n      enableTracking: true\n    };\n    detector = await poseDetection.createDetector(model, detectorConfig);\n  }\n\n  async function detect(detector) {\n    if (typeof webcam === \"undefined\" || webcam === null) return;\n    if (webcam.video.readyState !== 4) return;\n    if (!detector) return;\n    return await detector.estimatePoses(webcam.video);\n  }\n\n  function drawCanvas(poses, videoWidth, videoHeight) {\n    ctx.drawImage(webcam.video, 0, 0, videoWidth, videoHeight);\n    drawResults(poses, ctx, 0);\n  }\n\n  async function renderResult() {\n    if (!detector) return;\n    const poses = await detect(detector);\n    drawCanvas(poses, webcam.video.videoWidth, webcam.video.videoHeight);\n  } // Loop to render new skeleton pose and video every frame\n\n\n  async function renderPrediction() {\n    await renderResult();\n    rafId = requestAnimationFrame(renderPrediction);\n\n    if (rafId) {}\n  }\n\n  async function run() {\n    setupCamera();\n    await setupDetector();\n    renderPrediction();\n  }\n\n  useEffect(() => {\n    console.log(\"LOADING ...\");\n    run();\n    console.log(\"DONE LOADING.\");\n  });\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    style: {\n      position: \"relative˝\"\n    },\n    children: [/*#__PURE__*/_jsxDEV(\"canvas\", {\n      // id=\"output\"\n      ref: canvasRef,\n      width: videoDim.width,\n      height: videoDim.height\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 83,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(Webcam // id=\"video\"\n    , {\n      ref: webcamRef,\n      playsInline: true,\n      style: {\n        WebkitTransform: \"scaleX(-1)\",\n        transform: \"scaleX(-1)\",\n        visibility: \"hidden\",\n        width: \"auto\",\n        height: \"auto\"\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 89,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 82,\n    columnNumber: 5\n  }, this);\n}\n\n_s(Camera, \"v4cpjlVQ0JCDZnPWaD3Z9DHNiTM=\");\n\n_c = Camera;\n\nvar _c;\n\n$RefreshReg$(_c, \"Camera\");","map":{"version":3,"sources":["/Users/alberttian/f21/playground/frontend/fencing-ai-frontend/src/components/Camera.jsx"],"names":["React","useRef","useEffect","poseDetection","Webcam","drawResults","videoDim","width","height","rafId","webcam","detector","canvas","ctx","Camera","webcamRef","canvasRef","setupCamera","current","console","log","video","videoWidth","getContext","translate","scale","setupDetector","model","SupportedModels","MoveNet","detectorConfig","modelType","movenet","MULTIPOSE_LIGHTNING","minPoseScore","enableTracking","createDetector","detect","readyState","estimatePoses","drawCanvas","poses","videoHeight","drawImage","renderResult","renderPrediction","requestAnimationFrame","run","position","WebkitTransform","transform","visibility"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,MAAhB,EAAwBC,SAAxB,QAAyC,OAAzC;AACA,OAAO,uBAAP;AACA,OAAO,gCAAP;AACA,OAAO,+BAAP;AACA,OAAO,KAAKC,aAAZ,MAA+B,mCAA/B;AACA,OAAOC,MAAP,MAAmB,cAAnB;AACA,SAASC,WAAT,QAA4B,oBAA5B;;AAEA,MAAMC,QAAQ,GAAG;AACfC,EAAAA,KAAK,EAAE,GADQ;AAEfC,EAAAA,MAAM,EAAE;AAFO,CAAjB;AAKA,IAAIC,KAAJ;AACA,IAAIC,MAAJ,EAAYC,QAAZ;AACA,IAAIC,MAAJ,EAAYC,GAAZ;AAEA,eAAe,SAASC,MAAT,GAAkB;AAAA;;AAC/B,QAAMC,SAAS,GAAGd,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMe,SAAS,GAAGf,MAAM,CAAC,IAAD,CAAxB;;AAEA,WAASgB,WAAT,GAAuB;AACrBP,IAAAA,MAAM,GAAGK,SAAS,CAACG,OAAnB;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAa,iBAAgBV,MAAM,CAACW,KAAP,CAAad,KAAM,EAAhD;AACAY,IAAAA,OAAO,CAACC,GAAR,CAAa,iBAAgBV,MAAM,CAACW,KAAP,CAAaC,UAAW,EAArD;AAEAV,IAAAA,MAAM,GAAGI,SAAS,CAACE,OAAnB;AACAL,IAAAA,GAAG,GAAGD,MAAM,CAACW,UAAP,CAAkB,IAAlB,CAAN;AACAV,IAAAA,GAAG,CAACW,SAAJ,CAAclB,QAAQ,CAACC,KAAvB,EAA8B,CAA9B;AACAM,IAAAA,GAAG,CAACY,KAAJ,CAAU,CAAC,CAAX,EAAc,CAAd;AACD;;AAED,iBAAeC,aAAf,GAA+B;AAC7B,UAAMC,KAAK,GAAGxB,aAAa,CAACyB,eAAd,CAA8BC,OAA5C;AACA,UAAMC,cAAc,GAAG;AACrBC,MAAAA,SAAS,EAAE5B,aAAa,CAAC6B,OAAd,CAAsBD,SAAtB,CAAgCE,mBADtB;AAErBC,MAAAA,YAAY,EAAE,GAFO;AAGrBC,MAAAA,cAAc,EAAE;AAHK,KAAvB;AAKAxB,IAAAA,QAAQ,GAAG,MAAMR,aAAa,CAACiC,cAAd,CAA6BT,KAA7B,EAAoCG,cAApC,CAAjB;AACD;;AAED,iBAAeO,MAAf,CAAsB1B,QAAtB,EAAgC;AAC9B,QAAI,OAAOD,MAAP,KAAkB,WAAlB,IAAiCA,MAAM,KAAK,IAAhD,EAAsD;AACtD,QAAIA,MAAM,CAACW,KAAP,CAAaiB,UAAb,KAA4B,CAAhC,EAAmC;AACnC,QAAI,CAAC3B,QAAL,EAAe;AAEf,WAAO,MAAMA,QAAQ,CAAC4B,aAAT,CAAuB7B,MAAM,CAACW,KAA9B,CAAb;AACD;;AAED,WAASmB,UAAT,CAAoBC,KAApB,EAA2BnB,UAA3B,EAAuCoB,WAAvC,EAAoD;AAClD7B,IAAAA,GAAG,CAAC8B,SAAJ,CAAcjC,MAAM,CAACW,KAArB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkCC,UAAlC,EAA8CoB,WAA9C;AACArC,IAAAA,WAAW,CAACoC,KAAD,EAAQ5B,GAAR,EAAa,CAAb,CAAX;AACD;;AAED,iBAAe+B,YAAf,GAA8B;AAC5B,QAAI,CAACjC,QAAL,EAAe;AACf,UAAM8B,KAAK,GAAG,MAAMJ,MAAM,CAAC1B,QAAD,CAA1B;AACA6B,IAAAA,UAAU,CAACC,KAAD,EAAQ/B,MAAM,CAACW,KAAP,CAAaC,UAArB,EAAiCZ,MAAM,CAACW,KAAP,CAAaqB,WAA9C,CAAV;AACD,GA1C8B,CA4C/B;;;AACA,iBAAeG,gBAAf,GAAkC;AAChC,UAAMD,YAAY,EAAlB;AACAnC,IAAAA,KAAK,GAAGqC,qBAAqB,CAACD,gBAAD,CAA7B;;AACA,QAAIpC,KAAJ,EAAW,CACV;AACF;;AAED,iBAAesC,GAAf,GAAqB;AACnB9B,IAAAA,WAAW;AACX,UAAMS,aAAa,EAAnB;AACAmB,IAAAA,gBAAgB;AACjB;;AAED3C,EAAAA,SAAS,CAAC,MAAM;AACdiB,IAAAA,OAAO,CAACC,GAAR,CAAY,aAAZ;AACA2B,IAAAA,GAAG;AACH5B,IAAAA,OAAO,CAACC,GAAR,CAAY,eAAZ;AACD,GAJQ,CAAT;AAKA,sBACE;AAAK,IAAA,KAAK,EAAE;AAAE4B,MAAAA,QAAQ,EAAE;AAAZ,KAAZ;AAAA,4BACE;AACE;AACA,MAAA,GAAG,EAAEhC,SAFP;AAGE,MAAA,KAAK,EAAEV,QAAQ,CAACC,KAHlB;AAIE,MAAA,MAAM,EAAED,QAAQ,CAACE;AAJnB;AAAA;AAAA;AAAA;AAAA,YADF,eAOE,QAAC,MAAD,CACE;AADF;AAEE,MAAA,GAAG,EAAEO,SAFP;AAGE,MAAA,WAAW,MAHb;AAIE,MAAA,KAAK,EAAE;AACLkC,QAAAA,eAAe,EAAE,YADZ;AAELC,QAAAA,SAAS,EAAE,YAFN;AAGLC,QAAAA,UAAU,EAAE,QAHP;AAIL5C,QAAAA,KAAK,EAAE,MAJF;AAKLC,QAAAA,MAAM,EAAE;AALH;AAJT;AAAA;AAAA;AAAA;AAAA,YAPF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAsBD;;GArFuBM,M;;KAAAA,M","sourcesContent":["import React, { useRef, useEffect } from \"react\";\nimport \"@tensorflow/tfjs-core\";\nimport \"@tensorflow/tfjs-backend-webgl\";\nimport \"@tensorflow/tfjs-backend-wasm\";\nimport * as poseDetection from \"@tensorflow-models/pose-detection\";\nimport Webcam from \"react-webcam\";\nimport { drawResults } from \"../utils/drawUtils\";\n\nconst videoDim = {\n  width: 640,\n  height: 380,\n};\n\nlet rafId;\nlet webcam, detector;\nlet canvas, ctx;\n\nexport default function Camera() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  function setupCamera() {\n    webcam = webcamRef.current;\n    console.log(`webcam width: ${webcam.video.width}`);\n    console.log(`webcam width: ${webcam.video.videoWidth}`);\n\n    canvas = canvasRef.current\n    ctx = canvas.getContext(\"2d\");\n    ctx.translate(videoDim.width, 0)\n    ctx.scale(-1, 1)\n  }\n\n  async function setupDetector() {\n    const model = poseDetection.SupportedModels.MoveNet;\n    const detectorConfig = {\n      modelType: poseDetection.movenet.modelType.MULTIPOSE_LIGHTNING,\n      minPoseScore: 0.2,\n      enableTracking: true,\n    };\n    detector = await poseDetection.createDetector(model, detectorConfig);\n  }\n\n  async function detect(detector) {\n    if (typeof webcam === \"undefined\" || webcam === null) return;\n    if (webcam.video.readyState !== 4) return;\n    if (!detector) return;\n\n    return await detector.estimatePoses(webcam.video);\n  }\n\n  function drawCanvas(poses, videoWidth, videoHeight) {\n    ctx.drawImage(webcam.video, 0, 0, videoWidth, videoHeight);\n    drawResults(poses, ctx, 0);\n  }\n\n  async function renderResult() {\n    if (!detector) return;\n    const poses = await detect(detector);\n    drawCanvas(poses, webcam.video.videoWidth, webcam.video.videoHeight)\n  }\n\n  // Loop to render new skeleton pose and video every frame\n  async function renderPrediction() {\n    await renderResult();\n    rafId = requestAnimationFrame(renderPrediction);\n    if (rafId) {\n    }\n  }\n\n  async function run() {\n    setupCamera();\n    await setupDetector();\n    renderPrediction();\n  }\n\n  useEffect(() => {\n    console.log(\"LOADING ...\");\n    run();\n    console.log(\"DONE LOADING.\");\n  });\n  return (\n    <div style={{ position: \"relative˝\" }}>\n      <canvas\n        // id=\"output\"\n        ref={canvasRef}\n        width={videoDim.width}\n        height={videoDim.height}\n      />\n      <Webcam\n        // id=\"video\"\n        ref={webcamRef}\n        playsInline\n        style={{\n          WebkitTransform: \"scaleX(-1)\",\n          transform: \"scaleX(-1)\",\n          visibility: \"hidden\",\n          width: \"auto\",\n          height: \"auto\",\n        }}\n      />\n    </div>\n  );\n}\n"]},"metadata":{},"sourceType":"module"}