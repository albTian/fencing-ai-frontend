{"ast":null,"code":"var _jsxFileName = \"/Users/alberttian/f21/playground/frontend/fencing-ai-frontend/src/components/Camera.jsx\",\n    _s = $RefreshSig$();\n\nimport React, { useRef, useEffect } from \"react\";\nimport \"@tensorflow/tfjs-core\";\nimport \"@tensorflow/tfjs-backend-webgl\";\nimport \"@tensorflow/tfjs-backend-wasm\";\nimport * as poseDetection from \"@tensorflow-models/pose-detection\";\nimport Webcam from \"react-webcam\";\nimport DrawUtil from \"../utils/drawUtils\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst videoConstraints = {\n  width: 1280,\n  height: 720,\n  facingMode: \"environment\"\n};\nconst MIN_SCORE = 0.25;\nlet rafId = 1;\nlet webcam, detector;\nlet canvas, ctx;\nlet drawer;\nexport default function Camera() {\n  _s();\n\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n  useEffect(() => {\n    run(); // eslint-disable-next-line\n  }, []);\n\n  async function run() {\n    console.log(\"loading...\");\n    setup();\n    await setupDetector();\n    await renderPrediction();\n    console.log(\"done loading\");\n  }\n\n  function setup() {\n    webcam = webcamRef.current;\n    webcam.video.muted = true;\n    webcam.video.audio = false;\n    webcam.video.autoPlay = true;\n    canvas = canvasRef.current;\n    ctx = canvas.getContext(\"2d\");\n    ctx.translate(videoConstraints.width, 0);\n    ctx.scale(-1, 1);\n    drawer = new DrawUtil(ctx, MIN_SCORE);\n  }\n\n  async function setupDetector() {\n    const model = poseDetection.SupportedModels.MoveNet;\n    const detectorConfig = {\n      modelType: poseDetection.movenet.modelType.MULTIPOSE_LIGHTNING,\n      minPoseScore: MIN_SCORE,\n      enableTracking: true\n    };\n    detector = await poseDetection.createDetector(model, detectorConfig);\n  }\n\n  async function detect(detector) {\n    // Null protection checks\n    if (typeof webcam === \"undefined\" || webcam === null) return;\n    if (webcam.video.readyState !== 4) return;\n    if (!detector) return;\n    return await detector.estimatePoses(webcam.video);\n  } // Loop to render new skeleton pose and video every frame\n\n\n  async function renderPrediction() {\n    if (!detector) return; // To get vercel to shut up\n\n    if (rafId) // Grab the poses from detector\n      var poses = await detect(detector); // Draw webcam video and poses onto canvas\n\n    ctx.drawImage(webcam.video, 0, 0, videoConstraints.width, videoConstraints.height);\n    drawer.drawResults(poses, ctx, MIN_SCORE);\n    rafId = requestAnimationFrame(renderPrediction);\n  }\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    style: {\n      position: \"relative\",\n      maxHeight: \"100vh\",\n      overflow: \"hidden\"\n    },\n    children: [/*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      width: videoConstraints.width,\n      height: videoConstraints.height,\n      muted: true\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 101,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(Webcam, {\n      ref: webcamRef,\n      playsInline: true,\n      muted: true,\n      width: videoConstraints.width,\n      height: videoConstraints.height,\n      videoConstraints: videoConstraints,\n      style: {\n        visibility: \"hidden\"\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 107,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 94,\n    columnNumber: 5\n  }, this);\n}\n\n_s(Camera, \"v4cpjlVQ0JCDZnPWaD3Z9DHNiTM=\");\n\n_c = Camera;\n\nvar _c;\n\n$RefreshReg$(_c, \"Camera\");","map":{"version":3,"sources":["/Users/alberttian/f21/playground/frontend/fencing-ai-frontend/src/components/Camera.jsx"],"names":["React","useRef","useEffect","poseDetection","Webcam","DrawUtil","videoConstraints","width","height","facingMode","MIN_SCORE","rafId","webcam","detector","canvas","ctx","drawer","Camera","webcamRef","canvasRef","run","console","log","setup","setupDetector","renderPrediction","current","video","muted","audio","autoPlay","getContext","translate","scale","model","SupportedModels","MoveNet","detectorConfig","modelType","movenet","MULTIPOSE_LIGHTNING","minPoseScore","enableTracking","createDetector","detect","readyState","estimatePoses","poses","drawImage","drawResults","requestAnimationFrame","position","maxHeight","overflow","visibility"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,MAAhB,EAAwBC,SAAxB,QAAyC,OAAzC;AACA,OAAO,uBAAP;AACA,OAAO,gCAAP;AACA,OAAO,+BAAP;AACA,OAAO,KAAKC,aAAZ,MAA+B,mCAA/B;AACA,OAAOC,MAAP,MAAmB,cAAnB;AACA,OAAOC,QAAP,MAAqB,oBAArB;;AAEA,MAAMC,gBAAgB,GAAG;AACvBC,EAAAA,KAAK,EAAE,IADgB;AAEvBC,EAAAA,MAAM,EAAE,GAFe;AAGvBC,EAAAA,UAAU,EAAE;AAHW,CAAzB;AAMA,MAAMC,SAAS,GAAG,IAAlB;AAEA,IAAIC,KAAK,GAAG,CAAZ;AACA,IAAIC,MAAJ,EAAYC,QAAZ;AACA,IAAIC,MAAJ,EAAYC,GAAZ;AACA,IAAIC,MAAJ;AAEA,eAAe,SAASC,MAAT,GAAkB;AAAA;;AAC/B,QAAMC,SAAS,GAAGjB,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMkB,SAAS,GAAGlB,MAAM,CAAC,IAAD,CAAxB;AAEAC,EAAAA,SAAS,CAAC,MAAM;AACdkB,IAAAA,GAAG,GADW,CAEd;AACD,GAHQ,EAGN,EAHM,CAAT;;AAKA,iBAAeA,GAAf,GAAqB;AACnBC,IAAAA,OAAO,CAACC,GAAR,CAAY,YAAZ;AACAC,IAAAA,KAAK;AACL,UAAMC,aAAa,EAAnB;AACA,UAAMC,gBAAgB,EAAtB;AACAJ,IAAAA,OAAO,CAACC,GAAR,CAAY,cAAZ;AACD;;AAED,WAASC,KAAT,GAAiB;AACfX,IAAAA,MAAM,GAAGM,SAAS,CAACQ,OAAnB;AACAd,IAAAA,MAAM,CAACe,KAAP,CAAaC,KAAb,GAAqB,IAArB;AACAhB,IAAAA,MAAM,CAACe,KAAP,CAAaE,KAAb,GAAqB,KAArB;AACAjB,IAAAA,MAAM,CAACe,KAAP,CAAaG,QAAb,GAAwB,IAAxB;AAEAhB,IAAAA,MAAM,GAAGK,SAAS,CAACO,OAAnB;AACAX,IAAAA,GAAG,GAAGD,MAAM,CAACiB,UAAP,CAAkB,IAAlB,CAAN;AACAhB,IAAAA,GAAG,CAACiB,SAAJ,CAAc1B,gBAAgB,CAACC,KAA/B,EAAsC,CAAtC;AACAQ,IAAAA,GAAG,CAACkB,KAAJ,CAAU,CAAC,CAAX,EAAc,CAAd;AAEAjB,IAAAA,MAAM,GAAG,IAAIX,QAAJ,CAAaU,GAAb,EAAkBL,SAAlB,CAAT;AACD;;AAED,iBAAec,aAAf,GAA+B;AAC7B,UAAMU,KAAK,GAAG/B,aAAa,CAACgC,eAAd,CAA8BC,OAA5C;AACA,UAAMC,cAAc,GAAG;AACrBC,MAAAA,SAAS,EAAEnC,aAAa,CAACoC,OAAd,CAAsBD,SAAtB,CAAgCE,mBADtB;AAErBC,MAAAA,YAAY,EAAE/B,SAFO;AAGrBgC,MAAAA,cAAc,EAAE;AAHK,KAAvB;AAKA7B,IAAAA,QAAQ,GAAG,MAAMV,aAAa,CAACwC,cAAd,CAA6BT,KAA7B,EAAoCG,cAApC,CAAjB;AACD;;AAED,iBAAeO,MAAf,CAAsB/B,QAAtB,EAAgC;AAC9B;AACA,QAAI,OAAOD,MAAP,KAAkB,WAAlB,IAAiCA,MAAM,KAAK,IAAhD,EAAsD;AACtD,QAAIA,MAAM,CAACe,KAAP,CAAakB,UAAb,KAA4B,CAAhC,EAAmC;AACnC,QAAI,CAAChC,QAAL,EAAe;AAEf,WAAO,MAAMA,QAAQ,CAACiC,aAAT,CAAuBlC,MAAM,CAACe,KAA9B,CAAb;AACD,GAhD8B,CAkD/B;;;AACA,iBAAeF,gBAAf,GAAkC;AAChC,QAAI,CAACZ,QAAL,EAAe,OADiB,CAEhC;;AACA,QAAIF,KAAJ,EACE;AACA,UAAIoC,KAAK,GAAG,MAAMH,MAAM,CAAC/B,QAAD,CAAxB,CAL8B,CAOhC;;AACAE,IAAAA,GAAG,CAACiC,SAAJ,CACEpC,MAAM,CAACe,KADT,EAEE,CAFF,EAGE,CAHF,EAIErB,gBAAgB,CAACC,KAJnB,EAKED,gBAAgB,CAACE,MALnB;AAOAQ,IAAAA,MAAM,CAACiC,WAAP,CAAmBF,KAAnB,EAA0BhC,GAA1B,EAA+BL,SAA/B;AAEAC,IAAAA,KAAK,GAAGuC,qBAAqB,CAACzB,gBAAD,CAA7B;AACD;;AAED,sBACE;AACE,IAAA,KAAK,EAAE;AACL0B,MAAAA,QAAQ,EAAE,UADL;AAELC,MAAAA,SAAS,EAAE,OAFN;AAGLC,MAAAA,QAAQ,EAAE;AAHL,KADT;AAAA,4BAOE;AACE,MAAA,GAAG,EAAElC,SADP;AAEE,MAAA,KAAK,EAAEb,gBAAgB,CAACC,KAF1B;AAGE,MAAA,MAAM,EAAED,gBAAgB,CAACE,MAH3B;AAIE,MAAA,KAAK;AAJP;AAAA;AAAA;AAAA;AAAA,YAPF,eAaE,QAAC,MAAD;AACE,MAAA,GAAG,EAAEU,SADP;AAEE,MAAA,WAAW,MAFb;AAGE,MAAA,KAAK,EAAE,IAHT;AAIE,MAAA,KAAK,EAAEZ,gBAAgB,CAACC,KAJ1B;AAKE,MAAA,MAAM,EAAED,gBAAgB,CAACE,MAL3B;AAME,MAAA,gBAAgB,EAAEF,gBANpB;AAOE,MAAA,KAAK,EAAE;AACLgD,QAAAA,UAAU,EAAE;AADP;AAPT;AAAA;AAAA;AAAA;AAAA,YAbF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AA2BD;;GAlGuBrC,M;;KAAAA,M","sourcesContent":["import React, { useRef, useEffect } from \"react\";\nimport \"@tensorflow/tfjs-core\";\nimport \"@tensorflow/tfjs-backend-webgl\";\nimport \"@tensorflow/tfjs-backend-wasm\";\nimport * as poseDetection from \"@tensorflow-models/pose-detection\";\nimport Webcam from \"react-webcam\";\nimport DrawUtil from \"../utils/drawUtils\";\n\nconst videoConstraints = {\n  width: 1280,\n  height: 720,\n  facingMode: \"environment\",\n};\n\nconst MIN_SCORE = 0.25;\n\nlet rafId = 1;\nlet webcam, detector;\nlet canvas, ctx;\nlet drawer;\n\nexport default function Camera() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  useEffect(() => {\n    run();\n    // eslint-disable-next-line\n  }, []);\n\n  async function run() {\n    console.log(\"loading...\");\n    setup();\n    await setupDetector();\n    await renderPrediction();\n    console.log(\"done loading\");\n  }\n\n  function setup() {\n    webcam = webcamRef.current;\n    webcam.video.muted = true\n    webcam.video.audio = false\n    webcam.video.autoPlay = true\n\n    canvas = canvasRef.current;\n    ctx = canvas.getContext(\"2d\");\n    ctx.translate(videoConstraints.width, 0);\n    ctx.scale(-1, 1);\n\n    drawer = new DrawUtil(ctx, MIN_SCORE);\n  }\n\n  async function setupDetector() {\n    const model = poseDetection.SupportedModels.MoveNet;\n    const detectorConfig = {\n      modelType: poseDetection.movenet.modelType.MULTIPOSE_LIGHTNING,\n      minPoseScore: MIN_SCORE,\n      enableTracking: true,\n    };\n    detector = await poseDetection.createDetector(model, detectorConfig);\n  }\n\n  async function detect(detector) {\n    // Null protection checks\n    if (typeof webcam === \"undefined\" || webcam === null) return;\n    if (webcam.video.readyState !== 4) return;\n    if (!detector) return;\n\n    return await detector.estimatePoses(webcam.video);\n  }\n\n  // Loop to render new skeleton pose and video every frame\n  async function renderPrediction() {\n    if (!detector) return;\n    // To get vercel to shut up\n    if (rafId)\n      // Grab the poses from detector\n      var poses = await detect(detector);\n\n    // Draw webcam video and poses onto canvas\n    ctx.drawImage(\n      webcam.video,\n      0,\n      0,\n      videoConstraints.width,\n      videoConstraints.height\n    );\n    drawer.drawResults(poses, ctx, MIN_SCORE);\n\n    rafId = requestAnimationFrame(renderPrediction);\n  }\n\n  return (\n    <div\n      style={{\n        position: \"relative\",\n        maxHeight: \"100vh\",\n        overflow: \"hidden\",\n      }}\n    >\n      <canvas\n        ref={canvasRef}\n        width={videoConstraints.width}\n        height={videoConstraints.height}\n        muted\n      />\n      <Webcam\n        ref={webcamRef}\n        playsInline\n        muted={true}\n        width={videoConstraints.width}\n        height={videoConstraints.height}\n        videoConstraints={videoConstraints}\n        style={{\n          visibility: \"hidden\",\n        }}\n      />\n    </div>\n  );\n}\n"]},"metadata":{},"sourceType":"module"}