{"ast":null,"code":"var _jsxFileName = \"/Users/alberttian/f21/playground/frontend/fencing-ai-frontend/src/components/Camera.jsx\",\n    _s = $RefreshSig$();\n\nimport React, { useRef, useEffect } from \"react\";\nimport \"@tensorflow/tfjs-core\";\nimport \"@tensorflow/tfjs-backend-webgl\";\nimport \"@tensorflow/tfjs-backend-wasm\";\nimport * as poseDetection from \"@tensorflow-models/pose-detection\";\nimport Webcam from \"react-webcam\";\nimport { drawResults } from \"../utils/drawUtils\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst videoDim = {\n  width: 1280,\n  height: 720\n};\nlet rafId;\nlet camera, detector;\nlet ctx;\nexport default function Camera() {\n  _s();\n\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  function setupCamera() {\n    camera = webcamRef.current;\n    ctx = canvasRef.current.getContext(\"2d\");\n  }\n\n  async function setupDetector() {\n    const model = poseDetection.SupportedModels.MoveNet;\n    const detectorConfig = {\n      modelType: poseDetection.movenet.modelType.MULTIPOSE_LIGHTNING,\n      minPoseScore: 0.2,\n      enableTracking: true\n    };\n    detector = await poseDetection.createDetector(model, detectorConfig);\n  }\n\n  async function detect(detector) {\n    if (typeof camera === \"undefined\" || camera === null) return;\n    if (camera.video.readyState !== 4) return;\n    if (!detector) return;\n    const video = camera.video;\n    const videoWidth = video.videoWidth;\n    const videoHeight = video.videoHeight;\n    camera.video.width = videoWidth;\n    camera.video.height = videoHeight;\n    const poses = await detector.estimatePoses(video);\n    drawCanvas(poses, videoWidth, videoHeight, canvasRef);\n  }\n\n  function drawCanvas(poses, videoWidth, videoHeight, canvas) {\n    const ctx = canvas.current.getContext(\"2d\");\n    canvas.current.videoWidth = videoWidth;\n    canvas.current.videoHeight = videoHeight;\n    drawResults(poses, ctx, 0);\n  }\n\n  async function renderResult() {\n    if (!detector) return;\n    await detect(detector);\n  }\n\n  async function renderPrediction() {\n    await renderResult();\n    rafId = requestAnimationFrame(renderPrediction);\n\n    if (rafId) {}\n  }\n\n  async function run() {\n    setupCamera();\n    await setupDetector();\n    renderPrediction();\n  }\n\n  useEffect(() => {\n    print(\"useEffect rerunning\");\n    run();\n  });\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    style: {\n      position: \"relative\"\n    },\n    children: [/*#__PURE__*/_jsxDEV(Webcam, {\n      ref: webcamRef,\n      mirrored: true,\n      style: {\n        position: \"absolute\",\n        width: videoDim.width,\n        height: videoDim.height,\n        left: 0,\n        top: 0\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 86,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      style: {\n        position: \"absolute\",\n        width: videoDim.width,\n        height: videoDim.height,\n        left: 0,\n        top: 0\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 97,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 85,\n    columnNumber: 5\n  }, this);\n}\n\n_s(Camera, \"v4cpjlVQ0JCDZnPWaD3Z9DHNiTM=\");\n\n_c = Camera;\n\nvar _c;\n\n$RefreshReg$(_c, \"Camera\");","map":{"version":3,"sources":["/Users/alberttian/f21/playground/frontend/fencing-ai-frontend/src/components/Camera.jsx"],"names":["React","useRef","useEffect","poseDetection","Webcam","drawResults","videoDim","width","height","rafId","camera","detector","ctx","Camera","webcamRef","canvasRef","setupCamera","current","getContext","setupDetector","model","SupportedModels","MoveNet","detectorConfig","modelType","movenet","MULTIPOSE_LIGHTNING","minPoseScore","enableTracking","createDetector","detect","video","readyState","videoWidth","videoHeight","poses","estimatePoses","drawCanvas","canvas","renderResult","renderPrediction","requestAnimationFrame","run","print","position","left","top"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,MAAhB,EAAwBC,SAAxB,QAAyC,OAAzC;AACA,OAAO,uBAAP;AACA,OAAO,gCAAP;AACA,OAAO,+BAAP;AACA,OAAO,KAAKC,aAAZ,MAA+B,mCAA/B;AACA,OAAOC,MAAP,MAAmB,cAAnB;AACA,SAASC,WAAT,QAA4B,oBAA5B;;AAEA,MAAMC,QAAQ,GAAG;AACfC,EAAAA,KAAK,EAAE,IADQ;AAEfC,EAAAA,MAAM,EAAE;AAFO,CAAjB;AAKA,IAAIC,KAAJ;AACA,IAAIC,MAAJ,EAAYC,QAAZ;AACA,IAAIC,GAAJ;AAEA,eAAe,SAASC,MAAT,GAAkB;AAAA;;AAC/B,QAAMC,SAAS,GAAGb,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMc,SAAS,GAAGd,MAAM,CAAC,IAAD,CAAxB;;AAEA,WAASe,WAAT,GAAuB;AACrBN,IAAAA,MAAM,GAAGI,SAAS,CAACG,OAAnB;AACAL,IAAAA,GAAG,GAAGG,SAAS,CAACE,OAAV,CAAkBC,UAAlB,CAA6B,IAA7B,CAAN;AACD;;AAED,iBAAeC,aAAf,GAA+B;AAC7B,UAAMC,KAAK,GAAGjB,aAAa,CAACkB,eAAd,CAA8BC,OAA5C;AACA,UAAMC,cAAc,GAAG;AACrBC,MAAAA,SAAS,EAAErB,aAAa,CAACsB,OAAd,CAAsBD,SAAtB,CAAgCE,mBADtB;AAErBC,MAAAA,YAAY,EAAE,GAFO;AAGrBC,MAAAA,cAAc,EAAE;AAHK,KAAvB;AAKAjB,IAAAA,QAAQ,GAAG,MAAMR,aAAa,CAAC0B,cAAd,CAA6BT,KAA7B,EAAoCG,cAApC,CAAjB;AACD;;AAED,iBAAeO,MAAf,CAAsBnB,QAAtB,EAAgC;AAC9B,QAAI,OAAOD,MAAP,KAAkB,WAAlB,IAAiCA,MAAM,KAAK,IAAhD,EAAsD;AACtD,QAAIA,MAAM,CAACqB,KAAP,CAAaC,UAAb,KAA4B,CAAhC,EAAmC;AACnC,QAAI,CAACrB,QAAL,EAAe;AAEf,UAAMoB,KAAK,GAAGrB,MAAM,CAACqB,KAArB;AACA,UAAME,UAAU,GAAGF,KAAK,CAACE,UAAzB;AACA,UAAMC,WAAW,GAAGH,KAAK,CAACG,WAA1B;AAEAxB,IAAAA,MAAM,CAACqB,KAAP,CAAaxB,KAAb,GAAqB0B,UAArB;AACAvB,IAAAA,MAAM,CAACqB,KAAP,CAAavB,MAAb,GAAsB0B,WAAtB;AAEA,UAAMC,KAAK,GAAG,MAAMxB,QAAQ,CAACyB,aAAT,CAAuBL,KAAvB,CAApB;AACAM,IAAAA,UAAU,CAACF,KAAD,EAAQF,UAAR,EAAoBC,WAApB,EAAiCnB,SAAjC,CAAV;AACD;;AAED,WAASsB,UAAT,CAAoBF,KAApB,EAA2BF,UAA3B,EAAuCC,WAAvC,EAAoDI,MAApD,EAA4D;AAC1D,UAAM1B,GAAG,GAAG0B,MAAM,CAACrB,OAAP,CAAeC,UAAf,CAA0B,IAA1B,CAAZ;AACAoB,IAAAA,MAAM,CAACrB,OAAP,CAAegB,UAAf,GAA4BA,UAA5B;AACAK,IAAAA,MAAM,CAACrB,OAAP,CAAeiB,WAAf,GAA6BA,WAA7B;AAEA7B,IAAAA,WAAW,CAAC8B,KAAD,EAAQvB,GAAR,EAAa,CAAb,CAAX;AACD;;AAED,iBAAe2B,YAAf,GAA8B;AAC5B,QAAI,CAAC5B,QAAL,EAAe;AACf,UAAMmB,MAAM,CAACnB,QAAD,CAAZ;AACD;;AAED,iBAAe6B,gBAAf,GAAkC;AAChC,UAAMD,YAAY,EAAlB;AACA9B,IAAAA,KAAK,GAAGgC,qBAAqB,CAACD,gBAAD,CAA7B;;AACA,QAAI/B,KAAJ,EAAW,CACV;AACF;;AAED,iBAAeiC,GAAf,GAAqB;AACnB1B,IAAAA,WAAW;AACX,UAAMG,aAAa,EAAnB;AACAqB,IAAAA,gBAAgB;AACjB;;AAEDtC,EAAAA,SAAS,CAAC,MAAM;AACdyC,IAAAA,KAAK,CAAC,qBAAD,CAAL;AACAD,IAAAA,GAAG;AACJ,GAHQ,CAAT;AAKA,sBACE;AAAK,IAAA,KAAK,EAAE;AAAEE,MAAAA,QAAQ,EAAE;AAAZ,KAAZ;AAAA,4BACE,QAAC,MAAD;AACE,MAAA,GAAG,EAAE9B,SADP;AAEE,MAAA,QAAQ,MAFV;AAGE,MAAA,KAAK,EAAE;AACL8B,QAAAA,QAAQ,EAAE,UADL;AAELrC,QAAAA,KAAK,EAAED,QAAQ,CAACC,KAFX;AAGLC,QAAAA,MAAM,EAAEF,QAAQ,CAACE,MAHZ;AAILqC,QAAAA,IAAI,EAAE,CAJD;AAKLC,QAAAA,GAAG,EAAE;AALA;AAHT;AAAA;AAAA;AAAA;AAAA,YADF,eAYE;AACE,MAAA,GAAG,EAAE/B,SADP;AAEE,MAAA,KAAK,EAAE;AACL6B,QAAAA,QAAQ,EAAE,UADL;AAELrC,QAAAA,KAAK,EAAED,QAAQ,CAACC,KAFX;AAGLC,QAAAA,MAAM,EAAEF,QAAQ,CAACE,MAHZ;AAILqC,QAAAA,IAAI,EAAE,CAJD;AAKLC,QAAAA,GAAG,EAAE;AALA;AAFT;AAAA;AAAA;AAAA;AAAA,YAZF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAyBD;;GA3FuBjC,M;;KAAAA,M","sourcesContent":["import React, { useRef, useEffect } from \"react\";\nimport \"@tensorflow/tfjs-core\";\nimport \"@tensorflow/tfjs-backend-webgl\";\nimport \"@tensorflow/tfjs-backend-wasm\";\nimport * as poseDetection from \"@tensorflow-models/pose-detection\";\nimport Webcam from \"react-webcam\";\nimport { drawResults } from \"../utils/drawUtils\";\n\nconst videoDim = {\n  width: 1280,\n  height: 720,\n};\n\nlet rafId;\nlet camera, detector;\nlet ctx;\n\nexport default function Camera() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  function setupCamera() {\n    camera = webcamRef.current;\n    ctx = canvasRef.current.getContext(\"2d\");\n  }\n\n  async function setupDetector() {\n    const model = poseDetection.SupportedModels.MoveNet;\n    const detectorConfig = {\n      modelType: poseDetection.movenet.modelType.MULTIPOSE_LIGHTNING,\n      minPoseScore: 0.2,\n      enableTracking: true,\n    };\n    detector = await poseDetection.createDetector(model, detectorConfig);\n  }\n\n  async function detect(detector) {\n    if (typeof camera === \"undefined\" || camera === null) return;\n    if (camera.video.readyState !== 4) return;\n    if (!detector) return;\n\n    const video = camera.video;\n    const videoWidth = video.videoWidth;\n    const videoHeight = video.videoHeight;\n\n    camera.video.width = videoWidth;\n    camera.video.height = videoHeight;\n\n    const poses = await detector.estimatePoses(video);\n    drawCanvas(poses, videoWidth, videoHeight, canvasRef);\n  }\n\n  function drawCanvas(poses, videoWidth, videoHeight, canvas) {\n    const ctx = canvas.current.getContext(\"2d\");\n    canvas.current.videoWidth = videoWidth;\n    canvas.current.videoHeight = videoHeight;\n\n    drawResults(poses, ctx, 0);\n  }\n\n  async function renderResult() {\n    if (!detector) return;\n    await detect(detector);\n  }\n\n  async function renderPrediction() {\n    await renderResult();\n    rafId = requestAnimationFrame(renderPrediction);\n    if (rafId) {\n    }\n  }\n\n  async function run() {\n    setupCamera();\n    await setupDetector();\n    renderPrediction();\n  }\n\n  useEffect(() => {\n    print(\"useEffect rerunning\");\n    run();\n  });\n\n  return (\n    <div style={{ position: \"relative\" }}>\n      <Webcam\n        ref={webcamRef}\n        mirrored\n        style={{\n          position: \"absolute\",\n          width: videoDim.width,\n          height: videoDim.height,\n          left: 0,\n          top: 0,\n        }}\n      />\n      <canvas\n        ref={canvasRef}\n        style={{\n          position: \"absolute\",\n          width: videoDim.width,\n          height: videoDim.height,\n          left: 0,\n          top: 0,\n        }}\n      />\n    </div>\n  );\n}\n"]},"metadata":{},"sourceType":"module"}