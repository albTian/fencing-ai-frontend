{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { BatchMatMul, util } from '@tensorflow/tfjs-core';\nimport { reshape } from './Reshape';\nlet wasmBatchMatMul;\n\nfunction setup(backend) {\n  wasmBatchMatMul = backend.wasm.cwrap(BatchMatMul, null\n  /* void */\n  , ['number', 'array', 'number', 'number', 'array', 'number', 'number', 'number', 'number' // out_id\n  ]);\n}\n\nfunction batchMatMul(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    a,\n    b\n  } = inputs;\n  const {\n    transposeA,\n    transposeB\n  } = attrs;\n\n  if (a.dtype !== 'float32' || b.dtype !== 'float32') {\n    throw new Error(`BatchMatMul for non non-float32 tensors not yet supported.`);\n  }\n\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n  const batchDimsCompatible = batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;\n  util.assert(aRank >= 2 && bRank >= 2 && batchDimsCompatible, () => `Error in matMul: the input batch dimensions must either be the ` + `same or at least one input batch dimension must be 1. Got input ` + `batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);\n  const outShapeOuterDims = batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n  util.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (` + `${innerShapeB}) of Tensors with shapes ${a.shape} and ` + `${b.shape} and transposeA=${transposeA}` + ` and transposeB=${transposeB} must match.`);\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB]; // The rest of the implementation is designed to operate on rank-3 tensors\n\n  const a3d = reshape({\n    inputs: {\n      x: a\n    },\n    backend,\n    attrs: {\n      shape: a3dShape\n    }\n  });\n  const b3d = reshape({\n    inputs: {\n      x: b\n    },\n    backend,\n    attrs: {\n      shape: b3dShape\n    }\n  });\n  const a3dId = backend.dataIdMap.get(a3d.dataId).id;\n  const b3dId = backend.dataIdMap.get(b3d.dataId).id;\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n  const out = backend.makeOutput([batchDim, leftDim, rightDim], a3d.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  const aShapeBytes = new Uint8Array(new Int32Array(a3d.shape).buffer);\n  const bShapeBytes = new Uint8Array(new Int32Array(b3d.shape).buffer);\n  wasmBatchMatMul(a3dId, aShapeBytes, a3d.shape.length, b3dId, bShapeBytes, b3d.shape.length, transposeA, transposeB, outId);\n  backend.disposeData(a3d.dataId);\n  backend.disposeData(b3d.dataId);\n  out.shape = outShape;\n  return out;\n}\n\nexport const batchMatMulConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: batchMatMul\n};","map":{"version":3,"sources":["../../src/kernels/BatchMatMul.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,WAAR,EAAoF,IAApF,QAA+F,uBAA/F;AAIA,SAAQ,OAAR,QAAsB,WAAtB;AAEA,IAAI,eAAJ;;AAKA,SAAS,KAAT,CAAe,OAAf,EAAmC;AACjC,EAAA,eAAe,GAAG,OAAO,CAAC,IAAR,CAAa,KAAb,CAAmB,WAAnB,EAAgC;AAAK;AAArC,IAAiD,CACjE,QADiE,EAEjE,OAFiE,EAGjE,QAHiE,EAIjE,QAJiE,EAKjE,OALiE,EAMjE,QANiE,EAOjE,QAPiE,EAQjE,QARiE,EASjE,QATiE,CAStD;AATsD,GAAjD,CAAlB;AAWD;;AAED,SAAS,WAAT,CAAqB,IAArB,EAIC;AACC,QAAM;AAAC,IAAA,MAAD;AAAS,IAAA,OAAT;AAAkB,IAAA;AAAlB,MAA2B,IAAjC;AACA,QAAM;AAAC,IAAA,CAAD;AAAI,IAAA;AAAJ,MAAS,MAAf;AACA,QAAM;AAAC,IAAA,UAAD;AAAa,IAAA;AAAb,MAA2B,KAAjC;;AAEA,MAAI,CAAC,CAAC,KAAF,KAAY,SAAZ,IAAyB,CAAC,CAAC,KAAF,KAAY,SAAzC,EAAoD;AAClD,UAAM,IAAI,KAAJ,CACF,4DADE,CAAN;AAED;;AAED,QAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;AACA,QAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;AAEA,QAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAH,GAAwB,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAtD;AACA,QAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAH,GAAwB,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAtD;AAEA,QAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAH,GAAwB,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAtD;AACA,QAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAH,GAAwB,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAtD;AAEA,QAAM,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd,EAAiB,CAAC,CAAlB,CAAnB;AACA,QAAM,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd,EAAiB,CAAC,CAAlB,CAAnB;AAEA,QAAM,SAAS,GAAG,IAAI,CAAC,aAAL,CAAmB,UAAnB,CAAlB;AACA,QAAM,SAAS,GAAG,IAAI,CAAC,aAAL,CAAmB,UAAnB,CAAlB;AAEA,QAAM,mBAAmB,GACrB,SAAS,KAAK,SAAd,IAA2B,SAAS,KAAK,CAAzC,IAA8C,SAAS,KAAK,CADhE;AAGA,EAAA,IAAI,CAAC,MAAL,CACI,KAAK,IAAI,CAAT,IAAc,KAAK,IAAI,CAAvB,IAA4B,mBADhC,EAEI,MAAM,iEAAA,GACF,kEADE,GAEF,wBAAwB,UAAU,UAAU,UAAU,IAJ9D;AAMA,QAAM,iBAAiB,GACnB,SAAS,GAAG,SAAZ,GAAwB,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd,EAAiB,CAAC,CAAlB,CAAxB,GAA+C,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd,EAAiB,CAAC,CAAlB,CADnD;AAEA,QAAM,QAAQ,GAAG,iBAAiB,CAAC,MAAlB,CAAyB,CAAC,WAAD,EAAc,WAAd,CAAzB,CAAjB;AAEA,EAAA,IAAI,CAAC,MAAL,CACI,WAAW,KAAK,WADpB,EAEI,MAAM,kCAAkC,WAAW,SAA7C,GACF,GAAG,WAAW,4BAA4B,CAAC,CAAC,KAAK,OAD/C,GAEF,GAAG,CAAC,CAAC,KAAK,mBAAmB,UAAU,EAFrC,GAGF,mBAAmB,UAAU,cALrC;AAOA,QAAM,QAAQ,GAAG,UAAU,GAAG,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAAH,GACG,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAD9B;AAEA,QAAM,QAAQ,GAAG,UAAU,GAAG,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAAH,GACG,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAD9B,CA/CD,CAkDC;;AACA,QAAM,GAAG,GAAG,OAAO,CAAC;AAAC,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE;AAAJ,KAAT;AAAiB,IAAA,OAAjB;AAA0B,IAAA,KAAK,EAAE;AAAC,MAAA,KAAK,EAAE;AAAR;AAAjC,GAAD,CAAnB;AACA,QAAM,GAAG,GAAG,OAAO,CAAC;AAAC,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE;AAAJ,KAAT;AAAiB,IAAA,OAAjB;AAA0B,IAAA,KAAK,EAAE;AAAC,MAAA,KAAK,EAAE;AAAR;AAAjC,GAAD,CAAnB;AAEA,QAAM,KAAK,GAAG,OAAO,CAAC,SAAR,CAAkB,GAAlB,CAAsB,GAAG,CAAC,MAA1B,EAAkC,EAAhD;AACA,QAAM,KAAK,GAAG,OAAO,CAAC,SAAR,CAAkB,GAAlB,CAAsB,GAAG,CAAC,MAA1B,EAAkC,EAAhD;AAEA,QAAM,OAAO,GAAG,UAAU,GAAG,GAAG,CAAC,KAAJ,CAAU,CAAV,CAAH,GAAkB,GAAG,CAAC,KAAJ,CAAU,CAAV,CAA5C;AACA,QAAM,QAAQ,GAAG,UAAU,GAAG,GAAG,CAAC,KAAJ,CAAU,CAAV,CAAH,GAAkB,GAAG,CAAC,KAAJ,CAAU,CAAV,CAA7C;AACA,QAAM,QAAQ,GAAG,IAAI,CAAC,GAAL,CAAS,SAAT,EAAoB,SAApB,CAAjB;AAEA,QAAM,GAAG,GAAG,OAAO,CAAC,UAAR,CAAmB,CAAC,QAAD,EAAW,OAAX,EAAoB,QAApB,CAAnB,EAAkD,GAAG,CAAC,KAAtD,CAAZ;AACA,QAAM,KAAK,GAAG,OAAO,CAAC,SAAR,CAAkB,GAAlB,CAAsB,GAAG,CAAC,MAA1B,EAAkC,EAAhD;AAEA,QAAM,WAAW,GAAG,IAAI,UAAJ,CAAe,IAAI,UAAJ,CAAe,GAAG,CAAC,KAAnB,EAA0B,MAAzC,CAApB;AACA,QAAM,WAAW,GAAG,IAAI,UAAJ,CAAe,IAAI,UAAJ,CAAe,GAAG,CAAC,KAAnB,EAA0B,MAAzC,CAApB;AAEA,EAAA,eAAe,CACX,KADW,EACJ,WADI,EACS,GAAG,CAAC,KAAJ,CAAU,MADnB,EAC2B,KAD3B,EACkC,WADlC,EAEX,GAAG,CAAC,KAAJ,CAAU,MAFC,EAEO,UAFP,EAEmB,UAFnB,EAE+B,KAF/B,CAAf;AAIA,EAAA,OAAO,CAAC,WAAR,CAAoB,GAAG,CAAC,MAAxB;AACA,EAAA,OAAO,CAAC,WAAR,CAAoB,GAAG,CAAC,MAAxB;AAEA,EAAA,GAAG,CAAC,KAAJ,GAAY,QAAZ;AACA,SAAO,GAAP;AACD;;AAED,OAAO,MAAM,iBAAiB,GAAiB;AAC7C,EAAA,UAAU,EAAE,WADiC;AAE7C,EAAA,WAAW,EAAE,MAFgC;AAG7C,EAAA,SAAS,EAAE,KAHkC;AAI7C,EAAA,UAAU,EAAE;AAJiC,CAAxC","sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, KernelConfig, KernelFunc, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {reshape} from './Reshape';\n\nlet wasmBatchMatMul: (\n    aId: number, aShape: Uint8Array, aShapeSize: number, bId: number,\n    bShape: Uint8Array, bShapeSize: number, transposeA: boolean,\n    transposeB: boolean, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmBatchMatMul = backend.wasm.cwrap(BatchMatMul, null /* void */, [\n    'number',  // a_id\n    'array',   // a_shape\n    'number',  // a_shape.length\n    'number',  // b_id\n    'array',   // b_shape\n    'number',  // b_shape.length\n    'number',  // transpose_a\n    'number',  // transpose_b\n    'number'   // out_id\n  ]);\n}\n\nfunction batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  backend: BackendWasm,\n  attrs: BatchMatMulAttrs\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  if (a.dtype !== 'float32' || b.dtype !== 'float32') {\n    throw new Error(\n        `BatchMatMul for non non-float32 tensors not yet supported.`);\n  }\n\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const batchDimsCompatible =\n      batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;\n\n  util.assert(\n      aRank >= 2 && bRank >= 2 && batchDimsCompatible,\n      () => `Error in matMul: the input batch dimensions must either be the ` +\n          `same or at least one input batch dimension must be 1. Got input ` +\n          `batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);\n\n  const outShapeOuterDims =\n      batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] :\n                                [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] :\n                                [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n\n  const a3dId = backend.dataIdMap.get(a3d.dataId).id;\n  const b3dId = backend.dataIdMap.get(b3d.dataId).id;\n\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const out = backend.makeOutput([batchDim, leftDim, rightDim], a3d.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const aShapeBytes = new Uint8Array(new Int32Array(a3d.shape).buffer);\n  const bShapeBytes = new Uint8Array(new Int32Array(b3d.shape).buffer);\n\n  wasmBatchMatMul(\n      a3dId, aShapeBytes, a3d.shape.length, b3dId, bShapeBytes,\n      b3d.shape.length, transposeA, transposeB, outId);\n\n  backend.disposeData(a3d.dataId);\n  backend.disposeData(b3d.dataId);\n\n  out.shape = outShape;\n  return out;\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: batchMatMul as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}