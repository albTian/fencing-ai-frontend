{"ast":null,"code":"import _classCallCheck from \"/Users/alberttian/f21/playground/frontend/fencing-ai-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nimport { useShapeUniforms } from './gpgpu_math';\nexport var DepthwiseConvPacked2DProgram = function DepthwiseConvPacked2DProgram(convInfo) {\n  var addBias = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  var activation = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n  var hasPreluActivation = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n  var hasLeakyReluAlpha = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n\n  _classCallCheck(this, DepthwiseConvPacked2DProgram);\n\n  this.variableNames = ['x', 'W'];\n  this.packedInputs = true;\n  this.packedOutput = true;\n  this.customUniforms = [{\n    name: 'pads',\n    type: 'ivec2'\n  }, {\n    name: 'strides',\n    type: 'ivec2'\n  }, {\n    name: 'dilations',\n    type: 'ivec2'\n  }, {\n    name: 'inDims',\n    type: 'ivec2'\n  }];\n  this.outputShape = convInfo.outShape;\n  this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);\n  var channelMul = convInfo.outChannels / convInfo.inChannels;\n  var padLeft = convInfo.padInfo.left;\n  var strideWidth = convInfo.strideWidth;\n  var dilationWidth = convInfo.dilationWidth;\n  var filterHeight = convInfo.filterHeight;\n  var filterWidth = convInfo.filterWidth;\n  var texelsAcross = filterWidth;\n  var mainLoop = \"\\n      int xR; int xC; int xCOffset;\\n      vec4 wTexel; vec4 previous; vec4 final;\";\n\n  for (var c = 0; c < filterWidth; c++) {\n    mainLoop += \"\\n          vec4 xTexelC\".concat(c * 2, \";\\n          int xTexelC\").concat(c * 2, \"Ready;\\n          vec4 xTexelC\").concat(c * 2 + 1, \";\\n          int xTexelC\").concat(c * 2 + 1, \"Ready;\\n          vec4 xC\").concat(c, \";\");\n  }\n  /**\n   * This vectorized implementation works by gathering the values needed for\n   * each output channel's dot product into vec4's and then multiplying them\n   * all together (this happens in the final double for-loop below). Most of\n   * the main loop consists of constructing these vec4's with the minimum\n   * number of texture2D calls, which means making use of all four returned\n   * values from a texture2D call at once.\n   */\n\n\n  for (var r = 0; r < filterHeight; r++) {\n    for (var _c = 0; _c < filterWidth; _c++) {\n      mainLoop += \"\\n          xTexelC\".concat(_c * 2, \" = vec4(0.0);\\n          xTexelC\").concat(_c * 2, \"Ready = 0;\\n          xTexelC\").concat(_c * 2 + 1, \" = vec4(0.0);\\n          xTexelC\").concat(_c * 2 + 1, \"Ready = 0;\\n          xC\").concat(_c, \" = vec4(0.0);\");\n    }\n\n    mainLoop += \"\\n        xR = xRCorner + \".concat(r, \" * dilations[0];\\n        if (xR >=0 && xR < inDims[0]) {\\n      \");\n\n    for (var texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {\n      var colIndex = texelC * 2;\n      mainLoop += \"\\n          xC = xCCorner + \".concat(colIndex * dilationWidth, \";\\n          \");\n\n      if (strideWidth === 1) {\n        if (colIndex < filterWidth) {\n          // If padding is odd, the outer texels have to be composed.\n          if (padLeft % 2 === 1) {\n            // TODO: Ensure vec4 previous does not result in redundant sample,\n            // and avoid setting xTexelRC's that exceed the boundary in the\n            // first place rather than resetting them to vec4(0)).\n            // To compute xCOffset:\n            // - If padding is odd, we must add 1 to ensure we ask for an\n            // even-numbered row.\n            // - We subtract 2 to access the previous texel.\n            mainLoop += \"\\n                xCOffset = xC + 1;\\n                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex, \" = getX(batch, xR, xCOffset, d1);\\n\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(colIndex, \"Ready = 1;\\n                }\\n              \"); // This texel has been read in previous iteration if the dilation\n            // is 1.\n\n            if (dilationWidth === 1 && colIndex > 0) {\n              mainLoop += \"\\n                xC\".concat(colIndex, \" = vec4(xTexelC\").concat(colIndex - 2, \".zw, xTexelC\").concat(colIndex, \".xy);\\n                \");\n            } else {\n              mainLoop += \"\\n                  xCOffset = xC + 1 - 2;\\n\\n                  if (xCOffset >= 0 && xCOffset < inDims[1]) {\\n                    previous = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= inDims[1]) {\\n                      previous.zw = vec2(0.0);\\n                    }\\n\\n                    xC\".concat(colIndex, \" = vec4(previous.zw, xTexelC\").concat(colIndex, \".xy);\\n                  } else {\\n                    xC\").concat(colIndex, \" = vec4(0.0, 0.0, xTexelC\").concat(colIndex, \".xy);\\n                  }\\n                  \");\n            }\n          } else {\n            // Padding is even, so xRC corresponds to a single texel.\n            mainLoop += \"\\n                if (xC >= 0 && xC < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(colIndex, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = xTexelC\").concat(colIndex, \";\\n                \");\n          }\n\n          if (colIndex + 1 < filterWidth) {\n            // If dilation is even, the second entry should match the first\n            // (either both are composed or both are single samples). But if\n            // dilation is odd, then the second entry should be the opposite\n            // of the first (if the first is composed, the second is a single\n            // sample, and vice versa.)\n            var nextTexelOffset = padLeft % 2 === 0 ? util.nearestLargerEven(dilationWidth) : dilationWidth;\n\n            if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {\n              mainLoop += \"\\n                  xCOffset = xC + imod(pads[1], 2) + \".concat(nextTexelOffset, \";\\n\\n                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                    xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xCOffset, d1);\\n\\n                    // Need to manually clear unused channels in case\\n                    // we're reading from recycled texture.\\n                    if (xCOffset + 1 >= inDims[1]) {\\n                      xTexelC\").concat(colIndex + 1, \".zw = vec2(0.0);\\n                    }\\n                    xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                  }\\n                  \"); // If dilation > 1 then the xRC's will not be able to share any\n              // values, so each xRC will require two unique calls to getX.\n\n              if (dilationWidth > 1) {\n                mainLoop += \"\\n                    xCOffset -= 2;\\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                      xTexelC\").concat(colIndex, \" = getX(batch, xR, xCOffset, d1);\\n                      xTexelC\").concat(colIndex, \"Ready = 1;\\n                    }\\n                    \");\n              }\n\n              mainLoop += \"\\n                  xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(colIndex, \".zw, xTexelC\").concat(colIndex + 1, \".xy);\\n                  \");\n            } else {\n              // If dilation is 1 and padding is odd, we have already read the\n              // texel when constructing the previous x value. Here we can\n              // simply skip the texture read.\n              if (nextTexelOffset === 1) {\n                mainLoop += \"\\n                    xC\".concat(colIndex + 1, \" = xTexelC\").concat(colIndex, \";\\n                    \");\n              } else {\n                mainLoop += \"\\n                    xCOffset = xC + \".concat(nextTexelOffset, \";\\n\\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                      xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xCOffset, d1);\\n                      if (xCOffset + 1 >= inDims[1]) {\\n                        xTexelC\").concat(colIndex + 1, \".zw = vec2(0.0);\\n                      }\\n                      xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                    }\\n\\n                    xC\").concat(colIndex + 1, \" = xTexelC\").concat(colIndex + 1, \";\\n                    \");\n              }\n            }\n          }\n        }\n      } else {\n        // stride === 2\n        if (colIndex < filterWidth) {\n          // Depending on whether padLeft is even or odd, we want either the\n          // xy or zw channels from X texels for xC${colIndex}. If padLeft is\n          // even, xC${colIndex +1} is simply the zw channels of texels we've\n          // already sampled. But if padLeft is odd, xC{$c + 1}.zw will\n          // need to come from the xy channels of a new texel, hence the `\n          // vec4\n          // final` initialized below.\n          if (padLeft % 2 === 1) {\n            mainLoop += \"\\n                xCOffset = xC + 1 - strides[1];\\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex, \" = getX(batch, xR, xCOffset, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xCOffset + 1 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(colIndex, \"Ready = 1;\\n                }\\n\\n                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xC + 1, d1);\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if (xC + 2 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex + 1, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = vec4(xTexelC\").concat(colIndex, \".zw, xTexelC\").concat(colIndex + 1, \".zw);\\n              \");\n\n            if (colIndex + 1 < filterWidth) {\n              mainLoop += \"\\n                  final = vec4(0.0);\\n                  xCOffset = xC + 1 + strides[1];\\n                  if(xCOffset >= 0 && xCOffset < inDims[1]) {\\n                    final = getX(batch, xR, xCOffset, d1);\\n                  }\\n                  xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(colIndex + 1, \".xy, final.xy);\\n                \");\n            }\n          } else {\n            mainLoop += \"\\n                if(xC >= 0 && xC < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex, \" = getX(batch, xR, xC, d1);\\n                  if (xC + 1 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                  }\\n                  xTexelC\").concat(colIndex, \"Ready = 1;\\n                }\\n\\n                xCOffset = xC + strides[1];\\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                  xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xCOffset, d1);\\n                  if (xCOffset + 1 >= inDims[1]) {\\n                    xTexelC\").concat(colIndex + 1, \".zw = vec2(0.);\\n                  }\\n                  xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                }\\n\\n                xC\").concat(colIndex, \" = vec4(\\n                  xTexelC\").concat(colIndex, \".xy, xTexelC\").concat(colIndex + 1, \".xy);\\n              \");\n\n            if (colIndex + 1 < filterWidth) {\n              mainLoop += \"\\n                  xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(colIndex, \".zw, xTexelC\").concat(colIndex + 1, \".zw);\\n                \");\n            }\n          }\n        }\n      } // localize the dotProd accumulation within the loop, the theory is for\n      // GPU with limited cache, accumulate sum across large amount of\n      // veriables will cause lots of cache misses. (i.e. 5x5 filter will have\n      // 50 variables)\n\n\n      if (colIndex < filterWidth) {\n        mainLoop += \"\\n            wTexel = getW(\".concat(r, \", \").concat(colIndex, \", d1, q);\\n            dotProd += xC\").concat(colIndex, \" * vec4(wTexel.xz, wTexel.xz);\\n          \");\n\n        if (colIndex + 1 < filterWidth) {\n          mainLoop += \"\\n              wTexel = getW(\".concat(r, \", \").concat(colIndex + 1, \", d1, q);\\n              dotProd += xC\").concat(colIndex + 1, \" * vec4(wTexel.xz, wTexel.xz);\\n            \");\n        }\n      }\n    }\n\n    mainLoop += \"\\n        }\\n      \";\n  }\n\n  var activationSnippet = '',\n      applyActivationSnippet = '';\n\n  if (activation) {\n    if (hasPreluActivation) {\n      activationSnippet = \"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \".concat(activation, \"\\n        }\");\n    } else if (hasLeakyReluAlpha) {\n      activationSnippet = \"vec4 activation(vec4 a) {\\n          vec4 b = getLeakyreluAlphaAtOutCoords();\\n          \".concat(activation, \"\\n        }\");\n    } else {\n      activationSnippet = \"vec4 activation(vec4 x) {\\n          \".concat(activation, \"\\n        }\");\n    }\n\n    applyActivationSnippet = \"result = activation(result);\";\n  }\n\n  var addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n\n  if (addBias) {\n    this.variableNames.push('bias');\n  }\n\n  if (hasPreluActivation) {\n    this.variableNames.push('preluActivationWeights');\n  }\n\n  if (hasLeakyReluAlpha) {\n    this.variableNames.push('leakyreluAlpha');\n  }\n\n  this.userCode = \"\\n      \".concat(activationSnippet, \"\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \").concat(channelMul, \";\\n        int q = d2 - d1 * \").concat(channelMul, \";\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\\n        vec4 dotProd = vec4(0.000000000000001);\\n\\n        \").concat(mainLoop, \"\\n\\n        vec4 result = dotProd - vec4(0.000000000000001);\\n        \").concat(addBiasSnippet, \"\\n        \").concat(applyActivationSnippet, \"\\n        setOutput(result);\\n      }\\n    \");\n};","map":{"version":3,"sources":["../src/conv_packed_gpu_depthwise.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAsB,IAAtB,QAAiC,uBAAjC;AAEA,SAAsB,gBAAtB,QAA6C,cAA7C;AAEA,WAAa,4BAAb,GAcE,sCACI,QADJ,EAG6B;AAAA,MAFU,OAEV,uEAFoB,KAEpB;AAAA,MADzB,UACyB,uEADJ,IACI;AAAA,MADE,kBACF,uEADuB,KACvB;AAAA,MAAzB,iBAAyB,uEAAL,KAAK;;AAAA;;AAhB7B,OAAA,aAAA,GAAgB,CAAC,GAAD,EAAM,GAAN,CAAhB;AACA,OAAA,YAAA,GAAe,IAAf;AACA,OAAA,YAAA,GAAe,IAAf;AAIA,OAAA,cAAA,GAAiB,CACf;AAAC,IAAA,IAAI,EAAE,MAAP;AAAe,IAAA,IAAI,EAAE;AAArB,GADe,EAEf;AAAC,IAAA,IAAI,EAAE,SAAP;AAAkB,IAAA,IAAI,EAAE;AAAxB,GAFe,EAGf;AAAC,IAAA,IAAI,EAAE,WAAP;AAAoB,IAAA,IAAI,EAAE;AAA1B,GAHe,EAIf;AAAC,IAAA,IAAI,EAAE,QAAP;AAAiB,IAAA,IAAI,EAAE;AAAvB,GAJe,CAAjB;AAWE,OAAK,WAAL,GAAmB,QAAQ,CAAC,QAA5B;AACA,OAAK,mBAAL,GAA2B,gBAAgB,CAAC,KAAK,WAAL,CAAiB,MAAlB,CAA3C;AACA,MAAM,UAAU,GAAG,QAAQ,CAAC,WAAT,GAAuB,QAAQ,CAAC,UAAnD;AACA,MAAM,OAAO,GAAG,QAAQ,CAAC,OAAT,CAAiB,IAAjC;AACA,MAAM,WAAW,GAAG,QAAQ,CAAC,WAA7B;AACA,MAAM,aAAa,GAAG,QAAQ,CAAC,aAA/B;AACA,MAAM,YAAY,GAAG,QAAQ,CAAC,YAA9B;AACA,MAAM,WAAW,GAAG,QAAQ,CAAC,WAA7B;AACA,MAAM,YAAY,GAAG,WAArB;AAEA,MAAI,QAAQ,yFAAZ;;AAIA,OAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,WAApB,EAAiC,CAAC,EAAlC,EAAsC;AACpC,IAAA,QAAQ,sCACU,CAAC,GAAG,CADd,qCAES,CAAC,GAAG,CAFb,2CAGU,CAAC,GAAG,CAAJ,GAAQ,CAHlB,qCAIS,CAAC,GAAG,CAAJ,GAAQ,CAJjB,sCAKK,CALL,MAAR;AAMD;AAED;;;;;;;AAOG;;;AACH,OAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,YAApB,EAAkC,CAAC,EAAnC,EAAuC;AACrC,SAAK,IAAI,EAAC,GAAG,CAAb,EAAgB,EAAC,GAAG,WAApB,EAAiC,EAAC,EAAlC,EAAsC;AACpC,MAAA,QAAQ,iCACG,EAAC,GAAG,CADP,6CAEG,EAAC,GAAG,CAFP,0CAGG,EAAC,GAAG,CAAJ,GAAQ,CAHX,6CAIG,EAAC,GAAG,CAAJ,GAAQ,CAJX,qCAKF,EALE,kBAAR;AAMD;;AACD,IAAA,QAAQ,wCACY,CADZ,sEAAR;;AAKA,SAAK,IAAI,MAAM,GAAG,CAAlB,EAAqB,MAAM,GAAG,CAAC,YAAY,GAAG,CAAhB,IAAqB,CAAnD,EAAsD,MAAM,EAA5D,EAAgE;AAC9D,UAAM,QAAQ,GAAG,MAAM,GAAG,CAA1B;AAEA,MAAA,QAAQ,0CACY,QAAQ,GAAG,aADvB,kBAAR;;AAIA,UAAI,WAAW,KAAK,CAApB,EAAuB;AACrB,YAAI,QAAQ,GAAG,WAAf,EAA4B;AAC1B;AACA,cAAI,OAAO,GAAG,CAAV,KAAgB,CAApB,EAAuB;AACrB;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA,YAAA,QAAQ,wHAGJ,QAHI,qDAIK,QAJL,iQASO,QATP,6EAWK,QAXL,kDAAR,CAVqB,CAwBrB;AACA;;AACA,gBAAI,aAAa,KAAK,CAAlB,IAAuB,QAAQ,GAAG,CAAtC,EAAyC;AACvC,cAAA,QAAQ,kCACJ,QADI,4BACsB,QAAQ,GAAG,CADjC,yBAEJ,QAFI,4BAAR;AAID,aALD,MAKO;AACL,cAAA,QAAQ,sdAYA,QAZA,yCAYuC,QAZvC,sEAcA,QAdA,sCAcoC,QAdpC,mDAAR;AAiBD;AACF,WAlDD,MAkDO;AACL;AACA,YAAA,QAAQ,wEACoC,QADpC,qDAEK,QAFL,mHAIO,QAJP,6EAMK,QANL,gEASF,QATE,uBASmB,QATnB,wBAAR;AAWD;;AAED,cAAI,QAAQ,GAAG,CAAX,GAAe,WAAnB,EAAgC;AAC9B;AACA;AACA;AACA;AACA;AAEA,gBAAM,eAAe,GAAG,OAAO,GAAG,CAAV,KAAgB,CAAhB,GACpB,IAAI,CAAC,iBAAL,CAAuB,aAAvB,CADoB,GAEpB,aAFJ;;AAIA,gBAAK,aAAa,GAAG,CAAhB,KAAsB,CAAtB,IAA2B,OAAO,GAAG,CAAV,KAAgB,CAA5C,IACC,aAAa,GAAG,CAAhB,KAAsB,CAAtB,IAA2B,OAAO,GAAG,CAAV,KAAgB,CADhD,EACoD;AAClD,cAAA,QAAQ,qEAC+B,eAD/B,wFAIJ,QAAQ,GAAG,CAJP,uDAKK,QAAQ,GAAG,CALhB,yQAUO,QAAQ,GAAG,CAVlB,iFAYK,QAAQ,GAAG,CAZhB,wDAAR,CADkD,CAiBlD;AACA;;AACA,kBAAI,aAAa,GAAG,CAApB,EAAuB;AACrB,gBAAA,QAAQ,4HAGJ,QAHI,yDAIK,QAJL,6EAKK,QALL,4DAAR;AAQD;;AAED,cAAA,QAAQ,oCACF,QAAQ,GAAG,CADT,4BAC4B,QAD5B,yBAEJ,QAAQ,GAAG,CAFP,8BAAR;AAID,aAnCD,MAmCO;AACL;AACA;AACA;AACA,kBAAI,eAAe,KAAK,CAAxB,EAA2B;AACzB,gBAAA,QAAQ,sCACF,QAAQ,GAAG,CADT,uBACuB,QADvB,4BAAR;AAGD,eAJD,MAIO;AACL,gBAAA,QAAQ,oDACY,eADZ,0FAIJ,QAAQ,GAAG,CAJP,yDAKK,QAAQ,GAAG,CALhB,uIAOO,QAAQ,GAAG,CAPlB,qFASK,QAAQ,GAAG,CAThB,wEAYF,QAAQ,GAAG,CAZT,uBAYuB,QAAQ,GAAG,CAZlC,4BAAR;AAcD;AACF;AACF;AACF;AACF,OA7ID,MA6IO;AAAG;AACR,YAAI,QAAQ,GAAG,WAAf,EAA4B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAI,OAAO,GAAG,CAAV,KAAgB,CAApB,EAAuB;AACrB,YAAA,QAAQ,oIAGJ,QAHI,qDAIK,QAJL,+PAQO,QARP,6EAUK,QAVL,6GAcJ,QAAQ,GAAG,CAdP,qDAeK,QAAQ,GAAG,CAfhB,uPAmBO,QAAQ,GAAG,CAnBlB,6EAqBK,QAAQ,GAAG,CArBhB,gEAwBF,QAxBE,4BAwBwB,QAxBxB,yBAyBJ,QAAQ,GAAG,CAzBP,0BAAR;;AA4BA,gBAAI,QAAQ,GAAG,CAAX,GAAe,WAAnB,EAAgC;AAC9B,cAAA,QAAQ,6QAMF,QAAQ,GAAG,CANT,4BAM4B,QAAQ,GAAG,CANvC,sCAAR;AAQD;AACF,WAvCD,MAuCO;AACL,YAAA,QAAQ,uEACmC,QADnC,qDAEK,QAFL,mHAIO,QAJP,6EAMK,QANL,8JAWJ,QAAQ,GAAG,CAXP,qDAYK,QAAQ,GAAG,CAZhB,+HAcO,QAAQ,GAAG,CAdlB,4EAgBK,QAAQ,GAAG,CAhBhB,gEAmBF,QAnBE,gDAoBK,QApBL,yBAoB4B,QAAQ,GAAG,CApBvC,0BAAR;;AAuBA,gBAAI,QAAQ,GAAG,CAAX,GAAe,WAAnB,EAAgC;AAC9B,cAAA,QAAQ,oCACF,QAAQ,GAAG,CADT,4BAC4B,QAD5B,yBAEJ,QAAQ,GAAG,CAFP,4BAAR;AAID;AACF;AACF;AACF,OApO6D,CAsO9D;AACA;AACA;AACA;;;AACA,UAAI,QAAQ,GAAG,WAAf,EAA4B;AAC1B,QAAA,QAAQ,0CACU,CADV,eACgB,QADhB,iDAES,QAFT,+CAAR;;AAKA,YAAI,QAAQ,GAAG,CAAX,GAAe,WAAnB,EAAgC;AAC9B,UAAA,QAAQ,4CACU,CADV,eACgB,QAAQ,GAAG,CAD3B,mDAES,QAAQ,GAAG,CAFpB,iDAAR;AAID;AACF;AACF;;AACD,IAAA,QAAQ,yBAAR;AAGD;;AAED,MAAI,iBAAiB,GAAG,EAAxB;AAAA,MAA4B,sBAAsB,GAAG,EAArD;;AACA,MAAI,UAAJ,EAAgB;AACd,QAAI,kBAAJ,EAAwB;AACtB,MAAA,iBAAiB,8GAEb,UAFa,gBAAjB;AAID,KALD,MAKO,IAAI,iBAAJ,EAAuB;AAC5B,MAAA,iBAAiB,sGAEb,UAFa,gBAAjB;AAID,KALM,MAKA;AACL,MAAA,iBAAiB,kDACb,UADa,gBAAjB;AAGD;;AAED,IAAA,sBAAsB,iCAAtB;AACD;;AAED,MAAM,cAAc,GAAG,OAAO,GAAG,iCAAH,GAAuC,EAArE;;AACA,MAAI,OAAJ,EAAa;AACX,SAAK,aAAL,CAAmB,IAAnB,CAAwB,MAAxB;AACD;;AAED,MAAI,kBAAJ,EAAwB;AACtB,SAAK,aAAL,CAAmB,IAAnB,CAAwB,wBAAxB;AACD;;AACD,MAAI,iBAAJ,EAAuB;AACrB,SAAK,aAAL,CAAmB,IAAnB,CAAwB,gBAAxB;AACD;;AAED,OAAK,QAAL,qBACI,iBADJ,yNAQoB,UARpB,0CASwB,UATxB,4OAgBM,QAhBN,mFAmBM,cAnBN,uBAoBM,sBApBN;AAwBD,CArXH","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\n\nimport {GPGPUProgram, useShapeUniforms} from './gpgpu_math';\n\nexport class DepthwiseConvPacked2DProgram implements GPGPUProgram {\n  variableNames = ['x', 'W'];\n  packedInputs = true;\n  packedOutput = true;\n  outputShape: number[];\n  userCode: string;\n  enableShapeUniforms: boolean;\n  customUniforms = [\n    {name: 'pads', type: 'ivec2' as const },\n    {name: 'strides', type: 'ivec2' as const },\n    {name: 'dilations', type: 'ivec2' as const },\n    {name: 'inDims', type: 'ivec2' as const },\n  ];\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: string = null, hasPreluActivation = false,\n      hasLeakyReluAlpha = false) {\n    this.outputShape = convInfo.outShape;\n    this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);\n    const channelMul = convInfo.outChannels / convInfo.inChannels;\n    const padLeft = convInfo.padInfo.left;\n    const strideWidth = convInfo.strideWidth;\n    const dilationWidth = convInfo.dilationWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const texelsAcross = filterWidth;\n\n    let mainLoop = `\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;`;\n\n    for (let c = 0; c < filterWidth; c++) {\n      mainLoop += `\n          vec4 xTexelC${c * 2};\n          int xTexelC${c * 2}Ready;\n          vec4 xTexelC${c * 2 + 1};\n          int xTexelC${c * 2 + 1}Ready;\n          vec4 xC${c};`;\n    }\n\n    /**\n     * This vectorized implementation works by gathering the values needed for\n     * each output channel's dot product into vec4's and then multiplying them\n     * all together (this happens in the final double for-loop below). Most of\n     * the main loop consists of constructing these vec4's with the minimum\n     * number of texture2D calls, which means making use of all four returned\n     * values from a texture2D call at once.\n     */\n    for (let r = 0; r < filterHeight; r++) {\n      for (let c = 0; c < filterWidth; c++) {\n        mainLoop += `\n          xTexelC${c * 2} = vec4(0.0);\n          xTexelC${c * 2}Ready = 0;\n          xTexelC${c * 2 + 1} = vec4(0.0);\n          xTexelC${c * 2 + 1}Ready = 0;\n          xC${c} = vec4(0.0);`;\n      }\n      mainLoop += `\n        xR = xRCorner + ${r} * dilations[0];\n        if (xR >=0 && xR < inDims[0]) {\n      `;\n\n      for (let texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {\n        const colIndex = texelC * 2;\n\n        mainLoop += `\n          xC = xCCorner + ${colIndex * dilationWidth};\n          `;\n\n        if (strideWidth === 1) {\n          if (colIndex < filterWidth) {\n            // If padding is odd, the outer texels have to be composed.\n            if (padLeft % 2 === 1) {\n              // TODO: Ensure vec4 previous does not result in redundant sample,\n              // and avoid setting xTexelRC's that exceed the boundary in the\n              // first place rather than resetting them to vec4(0)).\n\n              // To compute xCOffset:\n              // - If padding is odd, we must add 1 to ensure we ask for an\n              // even-numbered row.\n              // - We subtract 2 to access the previous texel.\n\n              mainLoop += `\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                  colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n              `;\n              // This texel has been read in previous iteration if the dilation\n              // is 1.\n              if (dilationWidth === 1 && colIndex > 0) {\n                mainLoop += `\n                xC${colIndex} = vec4(xTexelC${colIndex - 2}.zw, xTexelC${\n                    colIndex}.xy);\n                `;\n              } else {\n                mainLoop += `\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC${colIndex} = vec4(previous.zw, xTexelC${colIndex}.xy);\n                  } else {\n                    xC${colIndex} = vec4(0.0, 0.0, xTexelC${colIndex}.xy);\n                  }\n                  `;\n              }\n            } else {\n              // Padding is even, so xRC corresponds to a single texel.\n              mainLoop += `\n                if (xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n\n                xC${colIndex} = xTexelC${colIndex};\n                `;\n            }\n\n            if (colIndex + 1 < filterWidth) {\n              // If dilation is even, the second entry should match the first\n              // (either both are composed or both are single samples). But if\n              // dilation is odd, then the second entry should be the opposite\n              // of the first (if the first is composed, the second is a single\n              // sample, and vice versa.)\n\n              const nextTexelOffset = padLeft % 2 === 0 ?\n                  util.nearestLargerEven(dilationWidth) :\n                  dilationWidth;\n\n              if ((dilationWidth % 2 === 0 && padLeft % 2 === 1) ||\n                  (dilationWidth % 2 !== 0 && padLeft % 2 !== 1)) {\n                mainLoop += `\n                  xCOffset = xC + imod(pads[1], 2) + ${nextTexelOffset};\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                    colIndex + 1}Ready == 0) {\n                    xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      xTexelC${colIndex + 1}.zw = vec2(0.0);\n                    }\n                    xTexelC${colIndex + 1}Ready = 1;\n                  }\n                  `;\n\n                // If dilation > 1 then the xRC's will not be able to share any\n                // values, so each xRC will require two unique calls to getX.\n                if (dilationWidth > 1) {\n                  mainLoop += `\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                      colIndex}Ready == 0) {\n                      xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n                      xTexelC${colIndex}Ready = 1;\n                    }\n                    `;\n                }\n\n                mainLoop += `\n                  xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${\n                    colIndex + 1}.xy);\n                  `;\n              } else {\n                // If dilation is 1 and padding is odd, we have already read the\n                // texel when constructing the previous x value. Here we can\n                // simply skip the texture read.\n                if (nextTexelOffset === 1) {\n                  mainLoop += `\n                    xC${colIndex + 1} = xTexelC${colIndex};\n                    `;\n                } else {\n                  mainLoop += `\n                    xCOffset = xC + ${nextTexelOffset};\n\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                      colIndex + 1}Ready == 0) {\n                      xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= inDims[1]) {\n                        xTexelC${colIndex + 1}.zw = vec2(0.0);\n                      }\n                      xTexelC${colIndex + 1}Ready = 1;\n                    }\n\n                    xC${colIndex + 1} = xTexelC${colIndex + 1};\n                    `;\n                }\n              }\n            }\n          }\n        } else {  // stride === 2\n          if (colIndex < filterWidth) {\n            // Depending on whether padLeft is even or odd, we want either the\n            // xy or zw channels from X texels for xC${colIndex}. If padLeft is\n            // even, xC${colIndex +1} is simply the zw channels of texels we've\n            // already sampled. But if padLeft is odd, xC{$c + 1}.zw will\n            // need to come from the xy channels of a new texel, hence the `\n            // vec4\n            // final` initialized below.\n            if (padLeft % 2 === 1) {\n              mainLoop += `\n                xCOffset = xC + 1 - strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                  colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${\n                  colIndex + 1}Ready == 0) {\n                  xTexelC${colIndex + 1} = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= inDims[1]) {\n                    xTexelC${colIndex + 1}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex + 1}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(xTexelC${colIndex}.zw, xTexelC${\n                  colIndex + 1}.zw);\n              `;\n\n              if (colIndex + 1 < filterWidth) {\n                mainLoop += `\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + strides[1];\n                  if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC${colIndex + 1} = vec4(xTexelC${colIndex + 1}.xy, final.xy);\n                `;\n              }\n            } else {\n              mainLoop += `\n                if(xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                  xTexelC${colIndex} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC${colIndex}.zw = vec2(0.0);\n                  }\n                  xTexelC${colIndex}Ready = 1;\n                }\n\n                xCOffset = xC + strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                  colIndex + 1}Ready == 0) {\n                  xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${colIndex + 1}.zw = vec2(0.);\n                  }\n                  xTexelC${colIndex + 1}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(\n                  xTexelC${colIndex}.xy, xTexelC${colIndex + 1}.xy);\n              `;\n\n              if (colIndex + 1 < filterWidth) {\n                mainLoop += `\n                  xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${\n                    colIndex + 1}.zw);\n                `;\n              }\n            }\n          }\n        }\n\n        // localize the dotProd accumulation within the loop, the theory is for\n        // GPU with limited cache, accumulate sum across large amount of\n        // veriables will cause lots of cache misses. (i.e. 5x5 filter will have\n        // 50 variables)\n        if (colIndex < filterWidth) {\n          mainLoop += `\n            wTexel = getW(${r}, ${colIndex}, d1, q);\n            dotProd += xC${colIndex} * vec4(wTexel.xz, wTexel.xz);\n          `;\n\n          if (colIndex + 1 < filterWidth) {\n            mainLoop += `\n              wTexel = getW(${r}, ${colIndex + 1}, d1, q);\n              dotProd += xC${colIndex + 1} * vec4(wTexel.xz, wTexel.xz);\n            `;\n          }\n        }\n      }\n      mainLoop += `\n        }\n      `;\n    }\n\n    let activationSnippet = '', applyActivationSnippet = '';\n    if (activation) {\n      if (hasPreluActivation) {\n        activationSnippet = `vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`;\n      } else if (hasLeakyReluAlpha) {\n        activationSnippet = `vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`;\n      } else {\n        activationSnippet = `vec4 activation(vec4 x) {\n          ${activation}\n        }`;\n      }\n\n      applyActivationSnippet = `result = activation(result);`;\n    }\n\n    const addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n    if (hasLeakyReluAlpha) {\n      this.variableNames.push('leakyreluAlpha');\n    }\n\n    this.userCode = `\n      ${activationSnippet}\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${channelMul};\n        int q = d2 - d1 * ${channelMul};\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ${mainLoop}\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ${addBiasSnippet}\n        ${applyActivationSnippet}\n        setOutput(result);\n      }\n    `;\n  }\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}